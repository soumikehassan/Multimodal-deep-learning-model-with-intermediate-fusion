# -*- coding: utf-8 -*-
"""Multimodal Deep Learning Model with Intermediate Fusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1edY1JDXyA_5KJ5e-fKBTxzHWR1pe804q
"""

import tensorflow as tf
from tensorflow.keras import layers, models, Input, Model
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ==========================================
# 1. Data Acquisition & Preprocessing
# ==========================================

def load_and_prepare_data():
    # Load CIFAR-10 Image dataset (Real Image Data)
    (x_images, y_labels), (x_test_img, y_test_lbl) = cifar10.load_data()

    # Normalize Image Data (Scale 0-255 to 0-1)
    x_images = x_images.astype('float32') / 255.0
    x_test_img = x_test_img.astype('float32') / 255.0

    # Create "Real" Tabular Data from Images
    # Simulating metadata like sensor readings or patient vitals attached to the image
    def extract_tabular_features(img_batch):
        # 1. Mean Brightness (Grayscale)
        gray = np.mean(img_batch, axis=3)
        brightness = np.mean(gray, axis=(1,2))

        # 2. Color Channel Means (R, G, B averages)
        mean_r = np.mean(img_batch[:,:,:,0], axis=(1,2))
        mean_g = np.mean(img_batch[:,:,:,1], axis=(1,2))
        mean_b = np.mean(img_batch[:,:,:,2], axis=(1,2))

        # 3. Contrast (Std Dev of Grayscale)
        contrast = np.std(gray, axis=(1,2))

        # Stack into a tabular matrix (N_samples, 5_features)
        tabular_data = np.stack([brightness, mean_r, mean_g, mean_b, contrast], axis=1)
        return tabular_data

    print("Extracting tabular features from images...")
    x_tabular = extract_tabular_features(x_images)
    x_test_tabular = extract_tabular_features(x_test_img)

    # Scale Tabular Data (Crucial for Neural Networks)
    scaler = StandardScaler()
    x_tabular = scaler.fit_transform(x_tabular)
    x_test_tabular = scaler.transform(x_test_tabular)

    # Convert labels to categorical (One-hot encoding)
    num_classes = 10
    y_labels = to_categorical(y_labels, num_classes)
    y_test_lbl = to_categorical(y_test_lbl, num_classes)

    # Split training data into Train/Validation
    x_img_train, x_img_val, x_tab_train, x_tab_val, y_train, y_val = train_test_split(
        x_images, x_tabular, y_labels, test_size=0.2, random_state=42
    )

    return (x_img_train, x_tab_train, y_train), \
           (x_img_val, x_tab_val, y_val), \
           (x_test_img, x_test_tabular, y_test_lbl)

# Load data
train_ds, val_ds, test_ds = load_and_prepare_data()

# ==========================================
# 2. Define Intermediate Fusion Model
# ==========================================

def build_intermediate_fusion_model(img_shape, tab_shape, num_classes):

    # --- Branch 1: Image Processing (CNN) ---
    input_img = Input(shape=img_shape, name='image_input')

    # Convolutional layers to extract visual features
    x1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x1 = layers.MaxPooling2D((2, 2))(x1)
    x1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x1)
    x1 = layers.MaxPooling2D((2, 2))(x1)
    x1 = layers.Flatten()(x1)

    # Intermediate Dense Representation for Images
    img_features = layers.Dense(64, activation='relu', name='img_dense_embedding')(x1)

    # --- Branch 2: Tabular Processing (MLP) ---
    input_tab = Input(shape=(tab_shape,), name='tabular_input')

    # Dense layers to extract statistical features
    y1 = layers.Dense(16, activation='relu')(input_tab)
    y1 = layers.Dense(16, activation='relu')(y1)

    # Intermediate Dense Representation for Tabular Data
    tab_features = layers.Dense(64, activation='relu', name='tab_dense_embedding')(y1)

    # --- INTERMEDIATE FUSION LAYER ---
    # Here we merge the high-level features from both branches
    # This is the core of "Intermediate Fusion"
    fusion_layer = layers.Concatenate(name='intermediate_fusion')([img_features, tab_features])

    # --- Shared Classification Head (Post-Fusion) ---
    # The model now makes decisions based on the combined representation
    z = layers.Dense(64, activation='relu')(fusion_layer)
    z = layers.Dropout(0.5)(z) # Regularization
    output = layers.Dense(num_classes, activation='softmax')(z)

    # Create Model
    model = Model(inputs=[input_img, input_tab], outputs=output, name='Intermediate_Fusion_Model')
    return model

# ==========================================
# 3. Model Compilation & Training
# ==========================================

# Get shapes
img_shape = train_ds[0].shape[1:] # (32, 32, 3)
tab_shape = train_ds[1].shape[1]  # (5,)
num_classes = train_ds[2].shape[1] # 10

# Build model
model = build_intermediate_fusion_model(img_shape, tab_shape, num_classes)

# Compile
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Model Summary
model.summary()

print("\nStarting training...")
history = model.fit(
    x=[train_ds[0], train_ds[1]], # Pass data as a list: [Images, Tabular]
    y=train_ds[2],
    validation_data=([val_ds[0], val_ds[1]], val_ds[2]),
    epochs=50,  # Increase epochs for better results (e.g., 50)
    batch_size=64
)

# ==========================================
# 4. Evaluation & Prediction
# ==========================================

# Evaluate on Test Data
print("\nEvaluating on Test Data...")
loss, accuracy = model.evaluate(
    x=[test_ds[0], test_ds[1]],
    y=test_ds[2]
)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Make a Prediction on a single sample
sample_img = test_ds[0][0:1]    # Shape (1, 32, 32, 3)
sample_tab = test_ds[1][0:1]    # Shape (1, 5)

prediction = model.predict([sample_img, sample_tab])
predicted_class = np.argmax(prediction)
true_class = np.argmax(test_ds[2][0])

print(f"\nSample Prediction:")
print(f"Predicted Class: {predicted_class}")
print(f"True Class: {true_class}")